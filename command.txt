
kubeadm reset
sudo kubeadm init --apiserver-advertise-address=192.168.205.10 --ignore-preflight-errors=NumCPU --ignore-preflight-errors=Mem
sudo kubeadm init --control-plane-endpoint=192.168.205.10 --pod-network-cidr=10.244.0.0/24 --ignore-preflight-errors=NumCPU --ignore-preflight-errors=Mem --apiserver-advertise-address=192.168.205.10
workernode subnet - 10.244.1.0/24

kubeadm join 192.168.205.10:6443 --token 36kjle.4popecl2je1bzj82 \
        --discovery-token-ca-cert-hash sha256:5da0397b613983a2a5d42178b63a3872fd73c3d7023581105c140fdf3ab5741f
--pod-network-cidr=10.244.0.0/24

 sudo systemctl stop apparmor && sudo systemctl disable apparmor  && sudo systemctl restart containerd.service

 kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml
 kubectl apply -f ~/weave_daemonset-k8s.yaml

kubectl create deploy nginx --image=nginx --replicas=1
kubectl delete pods --all -n default
kubectl run dnsutils --image=tutum/dnsutils --restart=Never -it --rm

kubectl rollout restart deployments/nginx

kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
vim /run/flannel/subnet.env

kubectl cp subnet.env coredns-5dd5756b68-mbtls:/run/flannel/subnet.env
 
sudo vim /etc/sysconfig/kubelet   /etc/default/kubelet  
KUBELET_EXTRA_ARGS='--node-ip 192.168.205.10'
sudo systemctl restart kubelet

sudo kill -9 $(sudo lsof -t -i:10250)
sudo ifconfig enp0s3 10.0.2.14 netmask 255.255.255.0

kubeadm reset

kubectl get svc - cluster ip
on worker - route add 100.64.0.1 gw <your real master IP>

kubectl edit cm/kube-proxy -n kube-system
--cluster-cidr=10.96.0.0/30
kubectl logs weave-net-84vk5 -p -c weave -n kube-system

curl -sSL 'raw.githubusercontent.com/containerd/containerd/main/script/setup/install-cni' | bash

kubectl exec -it <pod-name> -n <namespace> -- bash
kubectl get pods --all-namespaces
kubectl run --image=weaveworks/hello-world hello

kubectl drain <node name> --delete-emptydir-data --force --ignore-daemonsets

kubeadm delete node

curl "http://127.0.0.1:6784/status"

export IPALLOC_RANGE=10.0.0.0/16

# store
ETCDCTL_API=3 etcdctl --endpoints=https://[10.0.2.15]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt \
     --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key \
          snapshot save /opt/snapshot-pre-boot.db
# restore
ETCDCTL_API=3 etcdctl --endpoints=https://[10.0.2.15]:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt \
     --name=master \
     --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key \
     --data-dir /var/lib/etcd-from-backup \
     --initial-cluster=master=https://10.0.2.15:2380 \
     --initial-cluster-token etcd-cluster-1 \
     --initial-advertise-peer-urls=https://10.0.2.15:2380 \
     snapshot restore /opt/snapshot-pre-boot.db

kubectl create deploy nginx-deployment --image nginx && kubectl scale deploy nginx-deployment --replicas 1
kubectl create deployment frontend --replicas=2 --image=nginx --dry-run=client -o yaml > frontend.yaml
sudo dhclient -r 10.0.2.15

kubectl exec <pod name> -- <command>

kubectl edit configmap coredns -n kube-system
   kubectl edit ds kube-proxy -n kube-system


kubectl patch node k8s-worker1 -p '{"spec":{"podCIDR":"10.244.1.0/24"}}'
kubectl get nodes -o jsonpath='{.items[*].spec.podCIDR}'

kubectl get services --all-namespaces -o wide
DNS=10.96.0.10 8.8.8.8 2001:4860:4860::8888
 > /etc/systemd/resolved.conf
iptables -P FORWARD ACCEPT
echo "net.ipv4.ip_forward=1" >> /etc/sysctl.conf
add dns cluster ip to /etc/resolv.conf

ifconfig cni0 down
ip link delete cni0

kubectl auth can-i --list --as=system:serviceaccount:my-ns:my-sa

setup checklist:
1. check kube-flannel pod running correct
2. check DNS by using nslookup
3. check kubectl top is running
4. check can ping pod from master
5. check can ssh in pod
6. check node can ping node

metrics
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml





#install metric server
curl -LO https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml 

 kubectl apply -f
 kubectl top
 
 # ingress controller nginx
 kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml
reload secret
kubectl wait --namespace ingress-nginx \
  --for=condition=ready pod \
  --selector=app.kubernetes.io/component=controller \
  --timeout=120s
expose: 

kubectl create ingress demo-localhost --class=nginx \
  --rule="demo.localdev.me/*=demo:80"
  kubectl port-forward --namespace=ingress-nginx service/ingress-nginx-controller 8080:80


allow pod ping from master:
1. edit etc/hosts on master
192.168.205.10 k8s-master k8s-master
192.168.205.11 k8s-worker1 k8s-worker1
2. add route
route add -net 10.244.1.0/24 gw k8s-master
route add -net 10.244.2.0/24 gw k8s-worker1 ?
sudo route add -net 10.244.1.0/24 gw k8s-worker1